{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33fc92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already stored this in seperate file\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class RatingsTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ratings, all_product_ids):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_product_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_product_ids):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['user_id_int'], ratings['product_id_int']))\n",
    "\n",
    "        num_negatives = 4\n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_product_ids)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_product_ids)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0fccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already stored this in seperate file\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, all_product_ids):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_product_ids = all_product_ids\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(RatingsTrainDataset(self.ratings, self.all_product_ids),\n",
    "                          batch_size=512, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09e424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already stored this in seperate file or we can create a seperate class that will contains all this 3 methods\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "def get_content_based_recommendations(product_id, company_id, offset, limit):\n",
    "    if not os.path.exists(company_id):\n",
    "        return []\n",
    "    \n",
    "    product_mapping_file = open(f'{company_id}/product_mapping.pkl', 'rb')\n",
    "    product_mapping = pickle.load(product_mapping_file)\n",
    "    \n",
    "    if product_id not in product_mapping.keys():\n",
    "        return []\n",
    "    else:\n",
    "        model_file = open(f'{company_id}/content_based_model.pkl', 'rb')\n",
    "        model = pickle.load(model_file)\n",
    "\n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        product_id = product_mapping[product_id]\n",
    "\n",
    "        indices = model['series']\n",
    "        cosine_sim = model['cosine_sim']\n",
    "        product_ids = pd.Series(reverse_product_mapping.keys(), index=range(len(reverse_product_mapping.keys())))\n",
    "        idx = indices[product_id]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "        if len(sim_scores) < offset+1:\n",
    "            return []\n",
    "        sim_scores = sim_scores[offset+1 : offset+1+limit if offset+1+limit <= len(sim_scores) else len(sim_scores)]\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "        return product_ids.iloc[product_indices].apply(lambda x : reverse_product_mapping.get(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71303c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def get_hybrid_recommendations(user_id, product_id, company_id, offset, limit):\n",
    "    if not os.path.exists(company_id):\n",
    "        return []\n",
    "    \n",
    "    original_user_file = open(f'{company_id}/user_mapping.pkl', 'rb')\n",
    "    original_user_ids = pickle.load(original_user_file)\n",
    "    \n",
    "    if user_id not in original_user_ids.keys():\n",
    "        return get_content_based_recommendations(product_id, company_id, offset, limit);\n",
    "    else:\n",
    "        product_mapping_file = open(f'{company_id}/product_mapping.pkl', 'rb')\n",
    "        product_mapping = pickle.load(product_mapping_file)\n",
    "        model_file = open(f'{company_id}/content_based_model.pkl', 'rb')\n",
    "        model = pickle.load(model_file)\n",
    "\n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        product_id = product_mapping[product_id]\n",
    "\n",
    "        indices = model['series']\n",
    "        cosine_sim = model['cosine_sim']\n",
    "        product_ids = pd.Series(reverse_product_mapping.keys(), index=range(len(reverse_product_mapping.keys())))\n",
    "        idx = indices[product_id]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "        product_ids = product_ids.iloc[product_indices].tolist()\n",
    "        all_product_ids = np.array(product_ids[0 : 1000 if 1000 <= len(product_ids) else len(product_ids)])\n",
    "    \n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        model_file = open(f'{company_id}/collaborative_filtering_model.pkl', 'rb')\n",
    "        model_data = pickle.load(model_file)\n",
    "        user_id = original_user_ids[user_id]\n",
    "        model = model_data['model']\n",
    "        user_interacted_items = model_data['interacted_items']\n",
    "        interacted_items = user_interacted_items[user_id]\n",
    "        not_interacted_items = list(set(all_product_ids) - set(interacted_items))\n",
    "        predicted_labels = np.squeeze(model(torch.tensor([user_id]*len(not_interacted_items)), torch.tensor(not_interacted_items)).detach().numpy())\n",
    "        items = [not_interacted_items[i] for i in np.argsort(predicted_labels)[::-1].tolist()]\n",
    "        if len(items) < offset+1:\n",
    "            return []\n",
    "        return [reverse_product_mapping.get(x) for x in items[offset : offset+limit if offset+limit <= len(items) else len(items)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32345a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B00BGGDVOO',\n",
       " 'B0002L5R78',\n",
       " 'B007BJHETS',\n",
       " 'B0079UAT0A',\n",
       " 'B002BH3I9U',\n",
       " 'B00007M1TZ',\n",
       " 'B00825BZUY',\n",
       " 'B009D79VH4',\n",
       " 'B00884WH74',\n",
       " 'B003ES5ZR8',\n",
       " 'B005U0M9B8',\n",
       " 'B005NGKR54',\n",
       " 'B001196H3S',\n",
       " 'B0097CZHAU',\n",
       " 'B00066FH1U',\n",
       " 'B0007Y794O',\n",
       " 'B005H3Q57M',\n",
       " 'B000UMX7FI',\n",
       " 'B001WM73P0',\n",
       " 'B004R7A9NU',\n",
       " 'B000067O5G',\n",
       " 'B005KSAG3S',\n",
       " 'B00FNPD1OY',\n",
       " 'B008U3038I',\n",
       " 'B002W3IXZW',\n",
       " 'B004RFBIUU',\n",
       " 'B003MQWN40',\n",
       " 'B0066636AS',\n",
       " 'B00F3SOHNU',\n",
       " 'B008X9ZBVI',\n",
       " 'B0008D76L0',\n",
       " 'B00ASLSQHK',\n",
       " 'B008LURQ76',\n",
       " 'B000BV8604',\n",
       " 'B003STVG80',\n",
       " 'B001H0BA24',\n",
       " 'B001NS828K',\n",
       " 'B0056YNA1Q',\n",
       " 'B0019CSVMW',\n",
       " 'B005QFH86S',\n",
       " 'B00HVT27B8',\n",
       " 'B0036WTDHK',\n",
       " 'B005OFFH5Y',\n",
       " 'B000EMWBV0',\n",
       " 'B0001D3K8A',\n",
       " 'B001TICH08',\n",
       " 'B00568BV68',\n",
       " 'B00BCGRX9M',\n",
       " 'B0009JB7GI',\n",
       " 'B002XVYZ82',\n",
       " 'B007B5WHTE',\n",
       " 'B004QK8FBG',\n",
       " 'B000EXR0SI',\n",
       " 'B001A5FH9S',\n",
       " 'B008X9Z7N0',\n",
       " 'B007B6YPAM',\n",
       " 'B0002SQ0A4',\n",
       " 'B001F6TXME',\n",
       " 'B00IVPU7DG',\n",
       " 'B000NB05MO',\n",
       " 'B009924TSY',\n",
       " 'B000VW2QRM',\n",
       " 'B007RESFYK',\n",
       " 'B00HQ883QW',\n",
       " 'B002J46IYW',\n",
       " 'B001FN3ZRQ',\n",
       " 'B004J8HWHI',\n",
       " 'B005HFYE1O',\n",
       " 'B00603RU9A',\n",
       " 'B004AM624C',\n",
       " 'B000BKY3Q6',\n",
       " 'B002OJN250',\n",
       " 'B009W34X5O',\n",
       " 'B005HSG3JC',\n",
       " 'B00428N9N6',\n",
       " 'B000089GN2',\n",
       " 'B0009F4OR6',\n",
       " 'B0002A9RFM',\n",
       " 'B0034CSUZ8',\n",
       " 'B005HQ50SO',\n",
       " 'B0012WXFO8',\n",
       " 'B001FSIT9K',\n",
       " 'B00DBA1VYU',\n",
       " 'B000PCVF3E',\n",
       " 'B0036R9YA6',\n",
       " 'B000V06UHQ',\n",
       " 'B005N130Y4',\n",
       " 'B00018MSNI',\n",
       " 'B009NUWRF4',\n",
       " 'B003L171KW',\n",
       " 'B001D9IWIY',\n",
       " 'B001OQQ01W',\n",
       " 'B00B9DQ2QI',\n",
       " 'B0009K9FZW',\n",
       " 'B002W6Z80C',\n",
       " 'B00B660GE2',\n",
       " 'B0025PKFUI',\n",
       " 'B00GJFGDUQ',\n",
       " 'B00BCGRYY6',\n",
       " 'B009FBIBKG']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hybrid_recommendations('A3J3BRHTDRFJ2G', 'B00005TQ09', 'xjkgkjshl', 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44cb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

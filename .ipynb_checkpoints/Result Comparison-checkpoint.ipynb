{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already stored this in seperate file\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class RatingsTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ratings, all_product_ids):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_product_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_product_ids):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['user_id_int'], ratings['product_id_int']))\n",
    "\n",
    "        num_negatives = 4\n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_product_ids)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_product_ids)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already stored this in seperate file\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, all_product_ids):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_product_ids = all_product_ids\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(RatingsTrainDataset(self.ratings, self.all_product_ids),\n",
    "                          batch_size=512, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "def get_content_based_recommendations(product_id, company_id, offset, limit):\n",
    "    if not os.path.exists(company_id):\n",
    "        return []\n",
    "    \n",
    "    product_mapping_file = open(f'{company_id}/product_mapping.pkl', 'rb')\n",
    "    product_mapping = pickle.load(product_mapping_file)\n",
    "    \n",
    "    if product_id not in product_mapping.keys():\n",
    "        return []\n",
    "    else:\n",
    "        model_file = open(f'{company_id}/content_based_model.pkl', 'rb')\n",
    "        model = pickle.load(model_file)\n",
    "\n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        product_id = product_mapping[product_id]\n",
    "\n",
    "        indices = model['series']\n",
    "        cosine_sim = model['cosine_sim']\n",
    "        product_ids = pd.Series(reverse_product_mapping.keys(), index=range(len(reverse_product_mapping.keys())))\n",
    "        idx = indices[product_id]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "        if len(sim_scores) < offset+1:\n",
    "            return []\n",
    "        sim_scores = sim_scores[offset+1 : offset+1+limit if offset+1+limit <= len(sim_scores) else len(sim_scores)]\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "        return product_ids.iloc[product_indices].apply(lambda x : reverse_product_mapping.get(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ec6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def get_hybrid_recommendations(user_id, product_id, company_id, offset, limit):\n",
    "    if not os.path.exists(company_id):\n",
    "        return []\n",
    "    \n",
    "    original_user_file = open(f'{company_id}/user_mapping.pkl', 'rb')\n",
    "    original_user_ids = pickle.load(original_user_file)\n",
    "    \n",
    "    if user_id not in original_user_ids.keys():\n",
    "        return get_content_based_recommendations(product_id, company_id, offset, limit);\n",
    "    else:\n",
    "        product_mapping_file = open(f'{company_id}/product_mapping.pkl', 'rb')\n",
    "        product_mapping = pickle.load(product_mapping_file)\n",
    "        model_file = open(f'{company_id}/content_based_model.pkl', 'rb')\n",
    "        model = pickle.load(model_file)\n",
    "\n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        product_id = product_mapping[product_id]\n",
    "\n",
    "        indices = model['series']\n",
    "        cosine_sim = model['cosine_sim']\n",
    "        product_ids = pd.Series(reverse_product_mapping.keys(), index=range(len(reverse_product_mapping.keys())))\n",
    "        idx = indices[product_id]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "        product_ids = product_ids.iloc[product_indices].tolist()\n",
    "        all_product_ids = np.array(product_ids[0 : 1000 if 1000 <= len(product_ids) else len(product_ids)])\n",
    "    \n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        model_file = open(f'{company_id}/collaborative_filtering_model.pkl', 'rb')\n",
    "        model_data = pickle.load(model_file)\n",
    "        user_id = original_user_ids[user_id]\n",
    "        model = model_data['model']\n",
    "        user_interacted_items = model_data['interacted_items']\n",
    "        interacted_items = user_interacted_items[user_id]\n",
    "        not_interacted_items = list(set(all_product_ids) - set(interacted_items))\n",
    "        predicted_labels = np.squeeze(model(torch.tensor([user_id]*len(not_interacted_items)), torch.tensor(not_interacted_items)).detach().numpy())\n",
    "        items = [not_interacted_items[i] for i in np.argsort(predicted_labels)[::-1].tolist()]\n",
    "        if len(items) < offset+1:\n",
    "            return []\n",
    "        return [reverse_product_mapping.get(x) for x in items[offset : offset+limit if offset+limit <= len(items) else len(items)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def get_collaborative_recommendations(user_id, company_id, offset, limit):\n",
    "    \n",
    "    if not os.path.exists(company_id):\n",
    "        return []\n",
    "    \n",
    "    original_user_file = open(f'{company_id}/user_mapping.pkl', 'rb')\n",
    "    original_user_ids = pickle.load(original_user_file)\n",
    "    \n",
    "    if user_id not in original_user_ids.keys():\n",
    "        return [];\n",
    "    else:\n",
    "        product_ids_file = open(f'{company_id}/reverse_product_mapping.pkl', 'rb')\n",
    "        reverse_product_mapping = pickle.load(product_ids_file)\n",
    "        model_file = open(f'{company_id}/collaborative_filtering_model.pkl', 'rb')\n",
    "        model_data = pickle.load(model_file)\n",
    "        user_id = original_user_ids[user_id]\n",
    "        model = model_data['model']\n",
    "        all_product_ids = model_data['product_ids']\n",
    "        user_interacted_items = model_data['interacted_items']\n",
    "        interacted_items = user_interacted_items[user_id]\n",
    "        not_interacted_items = list(set(all_product_ids) - set(interacted_items))\n",
    "        predicted_labels = np.squeeze(model(torch.tensor([user_id]*len(not_interacted_items)), torch.tensor(not_interacted_items)).detach().numpy())\n",
    "        items = [not_interacted_items[i] for i in np.argsort(predicted_labels)[::-1].tolist()]\n",
    "        if len(items) < offset+1:\n",
    "            return []\n",
    "        return [reverse_product_mapping.get(x) for x in items[offset : offset+limit if offset+limit <= len(items) else len(items)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = get_content_based_recommendations('B00005TQ09', 'xjkgkjshl', 0, 10)\n",
    "hr = get_hybrid_recommendations('A3J3BRHTDRFJ2G', 'B00005TQ09', 'xjkgkjshl', 0, 10)\n",
    "cr = get_collaborative_recommendations('A3J3BRHTDRFJ2G', 'xjkgkjshl', 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e80ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbr = data[data['product_id'].str in cb].title\n",
    "hrr = data[data['product_id'].str in hr].title\n",
    "crr = data[data['product_id'].str in cr].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53440c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from tabulate import tabulate\n",
    "\n",
    "# assign data\n",
    "mydata = zip(cbr, crr, hrr)\n",
    " \n",
    "# create header\n",
    "head = [\"Content Based\", \"Collaborative\", \"Hybrid\"]\n",
    " \n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de12034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa18d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca202d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1af07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

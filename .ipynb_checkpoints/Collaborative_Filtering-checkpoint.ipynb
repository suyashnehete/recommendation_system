{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5wDzmoRF57V",
    "outputId": "68debf1e-9575-4329-da12-65a65c0aaaa8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "J5D7jN3MIEsz",
    "outputId": "7b2eabce-f36c-4f0e-e0ea-b976613e41ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 219587 rows of data from 12747 users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40396</td>\n",
       "      <td>3893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1396051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35978</td>\n",
       "      <td>3893</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1362268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40335</td>\n",
       "      <td>3893</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1402876800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9330</td>\n",
       "      <td>3893</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1360713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15824</td>\n",
       "      <td>3893</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1380326400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  rating   timestamp\n",
       "6     40396        3893     1.0  1396051200\n",
       "8     35978        3893     4.0  1362268800\n",
       "13    40335        3893     5.0  1402876800\n",
       "14     9330        3893     5.0  1360713600\n",
       "17    15824        3893     5.0  1380326400"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ratings = pd.read_csv('ratings.csv', parse_dates=['timestamp'])\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder2 = LabelEncoder()\n",
    "\n",
    "ratings['user_id'] = encoder1.fit_transform(ratings['user_id'])\n",
    "ratings['product_id'] = encoder2.fit_transform(ratings['product_id'])\n",
    "rand_user_ids = np.random.choice(ratings['user_id'].unique(), \n",
    "                                size=int(len(ratings['user_id'].unique())*0.3), \n",
    "                                replace=False)\n",
    "ratings = ratings.loc[ratings['user_id'].isin(rand_user_ids)]\n",
    "\n",
    "print('There are {} rows of data from {} users'.format(len(ratings), len(rand_user_ids)))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XyJvqYEJIZ2F"
   },
   "outputs": [],
   "source": [
    "ratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'] != 1]\n",
    "test_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "\n",
    "# drop columns that we no longer need\n",
    "train_ratings = train_ratings[['user_id', 'product_id', 'rating']]\n",
    "test_ratings = test_ratings[['user_id', 'product_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3_jxRm7KI7dr",
    "outputId": "7a042be4-aed1-44aa-e359-40e6d8556221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430196</th>\n",
       "      <td>639</td>\n",
       "      <td>40602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419003</th>\n",
       "      <td>40658</td>\n",
       "      <td>6839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691590</th>\n",
       "      <td>16664</td>\n",
       "      <td>27299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538367</th>\n",
       "      <td>22885</td>\n",
       "      <td>9628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>36229</td>\n",
       "      <td>23179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id  rating\n",
       "430196      639       40602       1\n",
       "419003    40658        6839       1\n",
       "691590    16664       27299       1\n",
       "538367    22885        9628       1\n",
       "3175      36229       23179       1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.loc[:, 'rating'] = 1\n",
    "train_ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1D3X0ImHJEh6"
   },
   "outputs": [],
   "source": [
    "# Get a list of all Product IDs\n",
    "all_product_ids = ratings['product_id'].unique()\n",
    "\n",
    "# Placeholders that will hold the training data\n",
    "users, items, labels = [], [], []\n",
    "\n",
    "# This is the set of items that each user has interaction with\n",
    "user_item_set = set(zip(train_ratings['user_id'], train_ratings['product_id']))\n",
    "\n",
    "# 4:1 ratio of negative to positive samples\n",
    "num_negatives = 4\n",
    "\n",
    "for (u, i) in user_item_set:\n",
    "    users.append(u)\n",
    "    items.append(i)\n",
    "    labels.append(1) # items that the user has interacted with are positive\n",
    "    for _ in range(num_negatives):\n",
    "        # randomly select an item\n",
    "        negative_item = np.random.choice(all_product_ids) \n",
    "        # check that the user has not interacted with this item\n",
    "        while (u, negative_item) in user_item_set:\n",
    "            negative_item = np.random.choice(all_product_ids)\n",
    "        users.append(u)\n",
    "        items.append(negative_item)\n",
    "        labels.append(0) # items not interacted with are negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "A8lpj6nYJ0U7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class AmazonRatingsTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ratings, all_product_ids):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_product_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_product_ids):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['user_id'], ratings['product_id']))\n",
    "\n",
    "        num_negatives = 4\n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_product_ids)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_product_ids)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonRatingsValDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ratings, all_product_ids):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_product_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_product_ids):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['user_id'], ratings['product_id']))\n",
    "        \n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "        \n",
    "        # create negative samples for validation data\n",
    "        num_negatives = 99\n",
    "        for u in set(ratings['user_id']):\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_product_ids)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_product_ids)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "                \n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)\n",
    "    \n",
    "class AmazonRatingsTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ratings, all_product_ids):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_product_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_product_ids):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['user_id'], ratings['product_id']))\n",
    "        \n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "        \n",
    "        # create negative samples for test data\n",
    "        num_negatives = 99\n",
    "        for u in set(ratings['user_id']):\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_product_ids)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_product_ids)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "                \n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HsYo001tK29Y"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "# ...\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# replace: from pytorch_lightning.metrics import functional as FM\n",
    "# with the one below\n",
    "import torchmetrics\n",
    "\n",
    "# import lightning_flash, which we’ll use later\n",
    "import flash\n",
    "from flash.image import ImageClassifier, ImageClassificationData\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF)\n",
    "    \n",
    "        Args:\n",
    "            num_users (int): Number of unique users\n",
    "            num_items (int): Number of unique items\n",
    "            ratings (pd.DataFrame): Dataframe containing the product ratings for training\n",
    "            all_product_ids (list): List containing all product_id (train + test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, all_product_ids):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_product_ids = all_product_ids\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        # Pass through embedding layers\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        # Concat the two embedding layers\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        # Pass through dense layer\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        \n",
    "        #loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())    \n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        loss = loss_fn(torch.sigmoid(predicted_labels), labels.float())\n",
    "        preds = torch.sigmoid(predicted_labels) > 0.5\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        logits = self(user_input, item_input)\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        val_loss = loss_fn(torch.sigmoid(logits), labels.float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        val_acc = (preds == labels).float().mean()\n",
    "        self.log('val_loss', val_loss, on_step=True, on_epoch=True)\n",
    "        self.log('val_acc', val_acc, on_step=True, on_epoch=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(AmazonRatingsTrainDataset(self.ratings, self.all_product_ids),\n",
    "                          batch_size=512, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "# ...\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# replace: from pytorch_lightning.metrics import functional as FM\n",
    "# with the one below\n",
    "import torchmetrics\n",
    "\n",
    "# import lightning_flash, which we’ll use later\n",
    "import flash\n",
    "from flash.image import ImageClassifier, ImageClassificationData\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF)\n",
    "    \n",
    "        Args:\n",
    "            num_users (int): Number of unique users\n",
    "            num_items (int): Number of unique items\n",
    "            ratings (pd.DataFrame): Dataframe containing the product ratings for training\n",
    "            all_product_ids (list): List containing all product_id (train + test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, all_product_ids):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_product_ids = all_product_ids\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        # Pass through embedding layers\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        # Concat the two embedding layers\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        # Pass through dense layer\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        \n",
    "        # reshape labels tensor to have the same shape as predicted labels\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        \n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        loss = loss_fn(torch.sigmoid(predicted_labels), labels.float())\n",
    "        preds = torch.sigmoid(predicted_labels) > 0.5\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        logits = self(user_input, item_input)\n",
    "        # reshape labels tensor to have the same shape as predicted labels\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        val_loss = loss_fn(torch.sigmoid(logits), labels.float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        val_acc = (preds == labels).float().mean()\n",
    "        self.log('val_loss', val_loss)\n",
    "        self.log('val_acc', val_acc)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(AmazonRatingsTrainDataset(self.ratings, self.all_product_ids),\n",
    "                          batch_size=512, num_workers=0)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(AmazonRatingsValDataset(self.ratings, self.all_product_ids),\n",
    "                          batch_size=512, num_workers=0)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(AmazonRatingsTestDataset(self.ratings, self.all_product_ids),\n",
    "                          batch_size=512, num_workers=10)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "df1a38e7d30148c7aa6c8036d8ac074b",
      "8fdf7d5bc28e4e208ae17cee915035eb",
      "1bca2d5ef10240f9999efc8e2f60583e",
      "d5ea92a1d80c43a1a8fa3264275892fc",
      "e6688f220b1044ad8c2982bc685d96ff",
      "157e00db7a184aa5a030624726b672ff",
      "1d367a928d4b47ba978e1abc49800928",
      "91b4a9a47056433e934cf949d84a44a9",
      "ce70bf4472bd4660a413a819b4f77f6f",
      "8f25f90b36b24da5b2c658e16829fcd9",
      "a0432ada792a49c0a5b11a5ab7c8c43b"
     ]
    },
    "id": "iYjzfpBaQAR5",
    "outputId": "6bf590fe-783b-4919-f467-ef6a6eb8df0f"
   },
   "outputs": [],
   "source": [
    "#num_users = ratings['user_id'].max()\n",
    "num_users = ratings['user_id'].max()+1\n",
    "num_items = ratings['product_id'].max()+1\n",
    "#num_items = ratings['product_id'].max()+1\n",
    "all_product_ids = ratings['product_id'].unique()\n",
    "\n",
    "model = NCF(num_users, num_items, train_ratings, all_product_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "logger = pl_loggers.TensorBoardLogger('logs/')\n",
    "trainer = pl.Trainer(max_epochs=3,logger=logger, accelerator='auto', val_check_interval=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 339 K \n",
      "1 | item_embedding | Embedding | 440 K \n",
      "2 | fc1            | Linear    | 1.1 K \n",
      "3 | fc2            | Linear    | 2.1 K \n",
      "4 | output         | Linear    | 33    \n",
      "---------------------------------------------\n",
      "783 K     Trainable params\n",
      "0         Non-trainable params\n",
      "783 K     Total params\n",
      "3.136     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suyashnehete/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/suyashnehete/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc76ab0a2f94c42ab2cf7d40c85d1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': tensor(0.6931),\n",
       " 'train_acc': tensor(0.5720),\n",
       " 'val_loss': tensor(0.6931),\n",
       " 'val_acc': tensor(0.5911)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.3078, Train Acc: 0.8570, Val Loss: 0.2026, Val Acc: 0.9255, Hits: 0.5783\n",
      "Epoch [2/20], Train Loss: 0.2969, Train Acc: 0.8641, Val Loss: 0.2076, Val Acc: 0.9207, Hits: 0.5715\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     22\u001b[0m train_loss, train_correct, train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (user_ids, item_ids, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(user_ids, item_ids)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mAmazonRatingsTrainDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep = [20]\n",
    "bs = [128]\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# Instantiate the training and validation datasets and data loaders\n",
    "train_dataset = AmazonRatingsTrainDataset(train_ratings, all_product_ids)\n",
    "val_dataset = AmazonRatingsValDataset(test_ratings, all_product_ids)\n",
    "for num_epochs, batch_size in zip(ep, bs):\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Train the PyTorch model\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    hit_rate = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        for batch_idx, (user_ids, item_ids, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, item_ids)\n",
    "            loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            predicted = outputs > 0.5\n",
    "            train_correct += (predicted == labels.float().view(-1, 1)).sum().item()\n",
    "            train_total += len(labels)\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_acc = train_correct / train_total\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (user_ids, item_ids, labels) in enumerate(val_loader):\n",
    "                outputs = model(user_ids, item_ids)\n",
    "                loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                predicted = outputs > 0.5\n",
    "                val_correct += (predicted == labels.float().view(-1, 1)).sum().item()\n",
    "                val_total += len(labels)\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            val_acc = val_correct / val_total\n",
    "            val_accuracies.append(val_acc)\n",
    "        \n",
    "        # User-item pairs for testing\n",
    "        test_user_item_set = set(zip(test_ratings['user_id'], test_ratings['product_id']))\n",
    "\n",
    "        # Dict of all items that are interacted with by each user\n",
    "        user_interacted_items = ratings.groupby('user_id')['product_id'].apply(list).to_dict()\n",
    "\n",
    "        hits = []\n",
    "        for (u,i) in test_user_item_set:\n",
    "            interacted_items = user_interacted_items[u]\n",
    "            not_interacted_items = set(all_product_ids) - set(interacted_items)\n",
    "            selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "            test_items = selected_not_interacted + [i]\n",
    "            predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
    "                                                torch.tensor(test_items)).detach().numpy())\n",
    "\n",
    "            top25_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:25].tolist()]\n",
    "            if i in top25_items:\n",
    "                hits.append(1)\n",
    "            else:\n",
    "                hits.append(0)\n",
    "        hit_rate.append(np.average(hits))\n",
    "\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}, Hits: {:.4f}'.format(\n",
    "            epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, np.average(hits)))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f'cb/ep {num_epochs} bs {batch_size} tl vl.png')\n",
    "\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.plot(hit_rate, label='Hit Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f'cb/ep {num_epochs} bs {batch_size} ta va.png')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(val_losses, label='Validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(train_accs, val_accs):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accs, label='Training accuracy')\n",
    "    plt.plot(val_accs, label='Validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall(precision, recall, average_precision):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.step(recall, precision, where='post', label='Precision-Recall curve (AP = %0.2f)' % average_precision)\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1wTiHLwM_s6",
    "outputId": "3ddfc664-1045-4ade-8606-c26b6f2c63a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hit Ratio @ 25 is 0.61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# User-item pairs for testing\n",
    "test_user_item_set = set(zip(test_ratings['user_id'], test_ratings['product_id']))\n",
    "\n",
    "# Dict of all items that are interacted with by each user\n",
    "user_interacted_items = ratings.groupby('user_id')['product_id'].apply(list).to_dict()\n",
    "\n",
    "hits = []\n",
    "for (u,i) in test_user_item_set:\n",
    "    interacted_items = user_interacted_items[u]\n",
    "    not_interacted_items = set(all_product_ids) - set(interacted_items)\n",
    "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "    test_items = selected_not_interacted + [i]\n",
    "    predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
    "                                        torch.tensor(test_items)).detach().numpy())\n",
    "    \n",
    "    top25_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:25].tolist()]\n",
    "    if i in top25_items:\n",
    "        hits.append(1)\n",
    "    else:\n",
    "        hits.append(0)\n",
    "        \n",
    "print(\"The Hit Ratio @ 25 is {:.2f}\".format(np.average(hits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "u = 205424347\n",
    "if u not in ratings['user_id'].unique():\n",
    "    print('no')\n",
    "else:\n",
    "    interacted_items = user_interacted_items[u]\n",
    "    not_interacted_items = list(set(all_product_ids) - set(interacted_items))\n",
    "    predicted_labels = np.squeeze(model(torch.tensor([u]*len(not_interacted_items)), torch.tensor(not_interacted_items)).detach().numpy())\n",
    "    items = [not_interacted_items[i] for i in np.argsort(predicted_labels)[::-1][0:100].tolist()]\n",
    "    items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(20547, 37727),\n",
       " (27766, 36806),\n",
       " (8843, 741),\n",
       " (24778, 12907),\n",
       " (3184, 26286),\n",
       " (18206, 37061),\n",
       " (26541, 15784),\n",
       " (11386, 51957),\n",
       " (39189, 8481),\n",
       " (1959, 34577),\n",
       " (2861, 18170),\n",
       " (35603, 27266),\n",
       " (5215, 4253),\n",
       " (42040, 44574),\n",
       " (39408, 33142),\n",
       " (25477, 53188),\n",
       " (17327, 4295),\n",
       " (28888, 37785),\n",
       " (38492, 3076),\n",
       " (28218, 49102),\n",
       " (28633, 3035),\n",
       " (32622, 13916),\n",
       " (7736, 40663),\n",
       " (39771, 36577),\n",
       " (28848, 52881),\n",
       " (12312, 8967),\n",
       " (3823, 38408),\n",
       " (6079, 28615),\n",
       " (1458, 10095),\n",
       " (23569, 15436),\n",
       " (8428, 53493),\n",
       " (21904, 32315),\n",
       " (19064, 46783),\n",
       " (29629, 24584),\n",
       " (36261, 40899),\n",
       " (4650, 6551),\n",
       " (2521, 51848),\n",
       " (25534, 43751),\n",
       " (29615, 43375),\n",
       " (914, 34962),\n",
       " (16958, 44442),\n",
       " (2161, 38215),\n",
       " (19729, 19028),\n",
       " (1601, 18401),\n",
       " (14734, 54941),\n",
       " (19697, 50981),\n",
       " (30838, 47439),\n",
       " (19258, 54317),\n",
       " (4682, 45874),\n",
       " (20984, 450),\n",
       " (28506, 1516),\n",
       " (25827, 2575),\n",
       " (3957, 329),\n",
       " (31776, 47170),\n",
       " (13019, 31288),\n",
       " (10192, 33681),\n",
       " (39729, 31749),\n",
       " (36364, 52223),\n",
       " (10294, 47958),\n",
       " (17319, 52153),\n",
       " (34945, 34634),\n",
       " (5358, 30329),\n",
       " (33356, 7966),\n",
       " (20686, 36155),\n",
       " (31771, 5886),\n",
       " (15385, 51353),\n",
       " (23908, 18756),\n",
       " (1178, 50361),\n",
       " (1398, 41962),\n",
       " (17131, 7486),\n",
       " (10507, 24509),\n",
       " (37510, 28484),\n",
       " (4159, 43187),\n",
       " (2202, 28955),\n",
       " (32978, 51067),\n",
       " (39745, 54738),\n",
       " (19408, 16475),\n",
       " (26208, 39019),\n",
       " (26386, 51857),\n",
       " (40684, 39152),\n",
       " (6934, 54109),\n",
       " (26118, 18565),\n",
       " (20031, 45915),\n",
       " (29630, 38906),\n",
       " (24168, 13583),\n",
       " (25065, 29592),\n",
       " (4343, 52285),\n",
       " (16551, 616),\n",
       " (20874, 54942),\n",
       " (33632, 50251),\n",
       " (26942, 14518),\n",
       " (16496, 54839),\n",
       " (11748, 36470),\n",
       " (10319, 10057),\n",
       " (27098, 52709),\n",
       " (9514, 238),\n",
       " (30208, 54051),\n",
       " (22817, 25855),\n",
       " (14922, 44923),\n",
       " (18354, 48797),\n",
       " (13444, 3076),\n",
       " (38989, 46595),\n",
       " (14921, 14456),\n",
       " (33479, 18114),\n",
       " (11947, 36572),\n",
       " (29450, 54409),\n",
       " (33100, 27880),\n",
       " (34985, 40546),\n",
       " (39346, 2775),\n",
       " (14948, 9634),\n",
       " (39253, 4304),\n",
       " (12377, 52600),\n",
       " (18065, 51848),\n",
       " (23028, 27206),\n",
       " (4711, 49540),\n",
       " (37283, 49594),\n",
       " (23744, 47829),\n",
       " (28593, 26320),\n",
       " (6189, 526),\n",
       " (21971, 16385),\n",
       " (13843, 54207),\n",
       " (17184, 53496),\n",
       " (12220, 53030),\n",
       " (30974, 54385),\n",
       " (36339, 39882),\n",
       " (26337, 50638),\n",
       " (28872, 30875),\n",
       " (13869, 11977),\n",
       " (10726, 44423),\n",
       " (5984, 33719),\n",
       " (11319, 54485),\n",
       " (22358, 45814),\n",
       " (17566, 52285),\n",
       " (29545, 37505),\n",
       " (7330, 54472),\n",
       " (23847, 53030),\n",
       " (31634, 7304),\n",
       " (32734, 38911),\n",
       " (35813, 53772),\n",
       " (23914, 37515),\n",
       " (42122, 47934),\n",
       " (22643, 53796),\n",
       " (31967, 51049),\n",
       " (22101, 13583),\n",
       " (39446, 52711),\n",
       " (12540, 52375),\n",
       " (13498, 54293),\n",
       " (14312, 48390),\n",
       " (21650, 48881),\n",
       " (15256, 49885),\n",
       " (36146, 36161),\n",
       " (38760, 21646),\n",
       " (10073, 8967),\n",
       " (29252, 9000),\n",
       " (36238, 43334),\n",
       " (15486, 37515),\n",
       " (14091, 33115),\n",
       " (39384, 53001),\n",
       " (4018, 14806),\n",
       " (19975, 50439),\n",
       " (38292, 49770),\n",
       " (2559, 20449),\n",
       " (26145, 44937),\n",
       " (3645, 38094),\n",
       " (28295, 1914),\n",
       " (25350, 23499),\n",
       " (6882, 41234),\n",
       " (34172, 40284),\n",
       " (24418, 36765),\n",
       " (22738, 46462),\n",
       " (20934, 26322),\n",
       " (38438, 51931),\n",
       " (40861, 42315),\n",
       " (1810, 17557),\n",
       " (25921, 42721),\n",
       " (7365, 48935),\n",
       " (1223, 36456),\n",
       " (34268, 43375),\n",
       " (809, 23341),\n",
       " (38538, 54498),\n",
       " (1243, 52909),\n",
       " (13250, 28577),\n",
       " (28585, 37597),\n",
       " (41415, 42837),\n",
       " (23114, 50361),\n",
       " (27889, 47427),\n",
       " (1362, 53769),\n",
       " (26820, 7963),\n",
       " (22246, 48336),\n",
       " (19869, 35733),\n",
       " (23650, 14383),\n",
       " (25797, 51666),\n",
       " (30256, 52374),\n",
       " (1978, 15276),\n",
       " (9015, 52285),\n",
       " (1384, 12322),\n",
       " (38816, 49645),\n",
       " (31835, 28746),\n",
       " (21435, 44337),\n",
       " (5288, 23095),\n",
       " (13605, 21692),\n",
       " (1832, 36806),\n",
       " (31195, 46358),\n",
       " (42241, 36806),\n",
       " (22106, 49645),\n",
       " (42293, 51225),\n",
       " (27061, 35244),\n",
       " (22188, 49943),\n",
       " (19689, 20876),\n",
       " (40317, 38148),\n",
       " (40939, 52949),\n",
       " (12200, 39814),\n",
       " (42088, 45050),\n",
       " (41516, 54916),\n",
       " (16590, 13361),\n",
       " (17766, 40119),\n",
       " (36459, 14366),\n",
       " (3334, 20515),\n",
       " (42015, 44922),\n",
       " (15389, 42654),\n",
       " (41410, 25106),\n",
       " (27326, 53046),\n",
       " (16691, 52784),\n",
       " (13974, 13658),\n",
       " (22327, 20314),\n",
       " (5179, 39151),\n",
       " (30880, 51921),\n",
       " (26536, 42569),\n",
       " (33782, 54317),\n",
       " (7600, 11675),\n",
       " (2386, 23341),\n",
       " (36813, 26090),\n",
       " (19724, 24603),\n",
       " (38854, 46917),\n",
       " (14505, 35696),\n",
       " (18534, 50140),\n",
       " (41733, 44714),\n",
       " (11597, 24366),\n",
       " (39678, 39450),\n",
       " (19046, 9641),\n",
       " (38055, 47695),\n",
       " (40089, 36806),\n",
       " (29904, 52285),\n",
       " (17535, 51604),\n",
       " (30913, 312),\n",
       " (4842, 48776),\n",
       " (35011, 41459),\n",
       " (35393, 37323),\n",
       " (17001, 1160),\n",
       " (4879, 14134),\n",
       " (32780, 51016),\n",
       " (35211, 43439),\n",
       " (28659, 47829),\n",
       " (36018, 43010),\n",
       " (16097, 39334),\n",
       " (20398, 49807),\n",
       " (7313, 54628),\n",
       " (15591, 1555),\n",
       " (14126, 52265),\n",
       " (25473, 53258),\n",
       " (30479, 25051),\n",
       " (27955, 48881),\n",
       " (8637, 43054),\n",
       " (6336, 9276),\n",
       " (25341, 52284),\n",
       " (27621, 40899),\n",
       " (42144, 51236),\n",
       " (11204, 52785),\n",
       " (27274, 52869),\n",
       " (27192, 33582),\n",
       " (9964, 24581),\n",
       " (20814, 54044),\n",
       " (18582, 26287),\n",
       " (22164, 52285),\n",
       " (8865, 28810),\n",
       " (36672, 42837),\n",
       " (34363, 47142),\n",
       " (6508, 53009),\n",
       " (5040, 9635),\n",
       " (7292, 44460),\n",
       " (11839, 53188),\n",
       " (4716, 45940),\n",
       " (36559, 29081),\n",
       " (37661, 53904),\n",
       " (39250, 53925),\n",
       " (1741, 26972),\n",
       " (8579, 47785),\n",
       " (34299, 22890),\n",
       " (7955, 24509),\n",
       " (37825, 11675),\n",
       " (20060, 11100),\n",
       " (24845, 9837),\n",
       " (39022, 53243),\n",
       " (25901, 45050),\n",
       " (24120, 6400),\n",
       " (14827, 50339),\n",
       " (13178, 25643),\n",
       " (23593, 44561),\n",
       " (3882, 6989),\n",
       " (33481, 41398),\n",
       " (18229, 55044),\n",
       " (20958, 49864),\n",
       " (6138, 19073),\n",
       " (38167, 51682),\n",
       " (26431, 53617),\n",
       " (21810, 30896),\n",
       " (32487, 53786),\n",
       " (2982, 54704),\n",
       " (25538, 37535),\n",
       " (9202, 53547),\n",
       " (30396, 46879),\n",
       " (2775, 23408),\n",
       " (13249, 35322),\n",
       " (28843, 51921),\n",
       " (30314, 10825),\n",
       " (17433, 18334),\n",
       " (8342, 50824),\n",
       " (9877, 48882),\n",
       " (30280, 28624),\n",
       " (20041, 53437),\n",
       " (11583, 50471),\n",
       " (24633, 18073),\n",
       " (38216, 40849),\n",
       " (22239, 8913),\n",
       " (38368, 37685),\n",
       " (26728, 189),\n",
       " (35655, 54409),\n",
       " (12607, 36915),\n",
       " (30347, 54170),\n",
       " (37038, 17135),\n",
       " (9982, 52732),\n",
       " (20497, 27265),\n",
       " (19432, 20525),\n",
       " (18027, 38792),\n",
       " (8990, 9812),\n",
       " (11306, 41387),\n",
       " (23064, 43937),\n",
       " (41624, 46207),\n",
       " (31563, 52862),\n",
       " (32488, 23341),\n",
       " (36891, 20276),\n",
       " (18482, 28755),\n",
       " (11429, 30877),\n",
       " (12443, 23342),\n",
       " (32653, 54182),\n",
       " (26266, 52223),\n",
       " (30587, 34530),\n",
       " (25058, 52079),\n",
       " (9377, 2529),\n",
       " (26682, 46917),\n",
       " (24106, 51632),\n",
       " (4892, 50033),\n",
       " (29300, 52523),\n",
       " (13481, 47591),\n",
       " (24600, 28755),\n",
       " (12369, 11500),\n",
       " (2589, 51645),\n",
       " (6154, 52399),\n",
       " (14378, 48782),\n",
       " (5018, 50374),\n",
       " (12042, 259),\n",
       " (23289, 4283),\n",
       " (35968, 36452),\n",
       " (36590, 46298),\n",
       " (2094, 54820),\n",
       " (39390, 28755),\n",
       " (12934, 37515),\n",
       " (42388, 37275),\n",
       " (8970, 54957),\n",
       " (16660, 39126),\n",
       " (5104, 19071),\n",
       " (16996, 24065),\n",
       " (21375, 50636),\n",
       " (34845, 52338),\n",
       " (41373, 49311),\n",
       " (856, 28123),\n",
       " (34888, 54923),\n",
       " (36377, 26713),\n",
       " (25368, 3084),\n",
       " (16433, 36905),\n",
       " (12625, 50945),\n",
       " (41993, 50224),\n",
       " (36156, 18608),\n",
       " (17472, 16531),\n",
       " (26405, 23762),\n",
       " (24965, 51605),\n",
       " (42051, 32378),\n",
       " (18409, 27206),\n",
       " (40562, 47039),\n",
       " (11672, 40447),\n",
       " (40837, 2655),\n",
       " (35088, 53641),\n",
       " (8707, 34962),\n",
       " (36014, 4151),\n",
       " (4167, 53025),\n",
       " (13151, 26007),\n",
       " (16460, 22634),\n",
       " (16494, 24204),\n",
       " (25598, 6636),\n",
       " (19670, 46545),\n",
       " (12363, 34787),\n",
       " (26282, 37776),\n",
       " (13934, 26123),\n",
       " (33529, 36688),\n",
       " (7350, 48466),\n",
       " (13944, 51428),\n",
       " (10519, 33944),\n",
       " (39937, 7703),\n",
       " (3999, 46917),\n",
       " (6800, 41088),\n",
       " (39941, 12023),\n",
       " (10252, 47829),\n",
       " (35049, 9484),\n",
       " (6675, 49724),\n",
       " (10251, 27484),\n",
       " (3740, 29660),\n",
       " (17170, 41052),\n",
       " (28092, 51732),\n",
       " (12475, 30948),\n",
       " (15986, 37101),\n",
       " (30352, 54890),\n",
       " (10100, 28483),\n",
       " (39316, 44401),\n",
       " (14116, 55002),\n",
       " (166, 1207),\n",
       " (25761, 33472),\n",
       " (16203, 36806),\n",
       " (31996, 624),\n",
       " (10226, 25855),\n",
       " (41278, 48390),\n",
       " (3600, 26095),\n",
       " (3597, 53639),\n",
       " (34442, 3972),\n",
       " (31845, 51904),\n",
       " (24653, 45051),\n",
       " (9757, 33863),\n",
       " (23946, 43883),\n",
       " (2726, 49101),\n",
       " (37238, 36682),\n",
       " (22334, 38960),\n",
       " (2244, 53033),\n",
       " (40682, 39361),\n",
       " (33799, 54726),\n",
       " (20630, 54450),\n",
       " (12406, 36604),\n",
       " (16196, 42135),\n",
       " (40759, 39544),\n",
       " (32686, 32225),\n",
       " (14405, 37506),\n",
       " (32002, 54187),\n",
       " (8398, 2032),\n",
       " (32740, 47737),\n",
       " (15744, 43997),\n",
       " (14044, 39190),\n",
       " (36507, 51106),\n",
       " (18343, 54986),\n",
       " (10232, 54508),\n",
       " (23472, 53533),\n",
       " (20607, 47003),\n",
       " (17969, 15377),\n",
       " (18807, 47213),\n",
       " (2744, 39477),\n",
       " (26150, 52774),\n",
       " (28546, 29698),\n",
       " (8996, 49872),\n",
       " (15197, 444),\n",
       " (30318, 54730),\n",
       " (28521, 36286),\n",
       " (31369, 21184),\n",
       " (41259, 48390),\n",
       " (1925, 2635),\n",
       " (24332, 44484),\n",
       " (27745, 26616),\n",
       " (6479, 22333),\n",
       " (27991, 23410),\n",
       " (24514, 51816),\n",
       " (24916, 28670),\n",
       " (30942, 51820),\n",
       " (14123, 49928),\n",
       " (18158, 38065),\n",
       " (16515, 34546),\n",
       " (12268, 47987),\n",
       " (6802, 42207),\n",
       " (9876, 10415),\n",
       " (20020, 13069),\n",
       " (28321, 22238),\n",
       " (8863, 24739),\n",
       " (25266, 3304),\n",
       " (4328, 43375),\n",
       " (35988, 54984),\n",
       " (897, 43375),\n",
       " (14276, 44922),\n",
       " (17395, 14593),\n",
       " (12643, 10371),\n",
       " (23039, 39664),\n",
       " (7853, 47965),\n",
       " (31844, 21305),\n",
       " (29814, 54530),\n",
       " (14382, 47829),\n",
       " (14259, 30231),\n",
       " (5190, 21419),\n",
       " (28409, 48136),\n",
       " (23232, 42947),\n",
       " (20300, 31260),\n",
       " (20935, 27341),\n",
       " (41873, 52467),\n",
       " (31533, 38567),\n",
       " (15130, 51371),\n",
       " (22704, 35594),\n",
       " (4179, 24714),\n",
       " (2677, 18202),\n",
       " (20079, 17971),\n",
       " (28136, 26514),\n",
       " (39508, 45765),\n",
       " (2572, 14244),\n",
       " (41550, 12594),\n",
       " (40535, 39152),\n",
       " (19422, 21313),\n",
       " (37723, 45051),\n",
       " (3717, 53178),\n",
       " (36024, 18023),\n",
       " (32136, 52042),\n",
       " (10341, 52828),\n",
       " (36178, 32719),\n",
       " (2378, 52285),\n",
       " (42234, 41519),\n",
       " (28618, 55012),\n",
       " (36519, 45292),\n",
       " (23496, 50991),\n",
       " (14139, 15883),\n",
       " (20074, 19963),\n",
       " (21907, 42790),\n",
       " (41072, 48109),\n",
       " (1069, 41923),\n",
       " (13953, 35385),\n",
       " (18531, 38259),\n",
       " (33322, 19071),\n",
       " (41992, 8859),\n",
       " (35701, 13290),\n",
       " (9194, 50866),\n",
       " (9408, 32136),\n",
       " (7071, 3094),\n",
       " (28544, 39935),\n",
       " (39465, 52834),\n",
       " (39349, 30028),\n",
       " (8588, 317),\n",
       " (42137, 50338),\n",
       " (23243, 46731),\n",
       " (3509, 53498),\n",
       " (41437, 55067),\n",
       " (35644, 46906),\n",
       " (23939, 37803),\n",
       " (9859, 45254),\n",
       " (5421, 40899),\n",
       " (22657, 51710),\n",
       " (26203, 16530),\n",
       " (11838, 50873),\n",
       " (40031, 53632),\n",
       " (29072, 18749),\n",
       " (7317, 50196),\n",
       " (22371, 33862),\n",
       " (28490, 18064),\n",
       " (8146, 11353),\n",
       " (2060, 17428),\n",
       " (23634, 54321),\n",
       " (29362, 53493),\n",
       " (17784, 30350),\n",
       " (17656, 43936),\n",
       " (18330, 54726),\n",
       " (17537, 4580),\n",
       " (4624, 47829),\n",
       " (7687, 32652),\n",
       " (28591, 50088),\n",
       " (39032, 30334),\n",
       " (39579, 28746),\n",
       " (16400, 23564),\n",
       " (36241, 35124),\n",
       " (37396, 52869),\n",
       " (25098, 23021),\n",
       " (39692, 53240),\n",
       " (19293, 43375),\n",
       " (18602, 26488),\n",
       " (9732, 31391),\n",
       " (15955, 42583),\n",
       " (3965, 51283),\n",
       " (12478, 49526),\n",
       " (25825, 23013),\n",
       " (41813, 46376),\n",
       " (10815, 47755),\n",
       " (7852, 53485),\n",
       " (1474, 44442),\n",
       " (34182, 39890),\n",
       " (24969, 54519),\n",
       " (36970, 53821),\n",
       " (29243, 9195),\n",
       " (9084, 25878),\n",
       " (10291, 37397),\n",
       " (29314, 26108),\n",
       " (17036, 22327),\n",
       " (21220, 25045),\n",
       " (30730, 47829),\n",
       " (16674, 54405),\n",
       " (38635, 25278),\n",
       " (349, 48618),\n",
       " (31817, 28206),\n",
       " (22700, 22386),\n",
       " (22845, 39477),\n",
       " (26981, 5560),\n",
       " (39428, 41129),\n",
       " (15100, 50942),\n",
       " (16238, 37515),\n",
       " (33349, 34597),\n",
       " (14231, 3955),\n",
       " (23004, 37026),\n",
       " (33655, 50330),\n",
       " (19710, 50092),\n",
       " (22998, 35262),\n",
       " (22792, 22325),\n",
       " (17088, 26287),\n",
       " (8375, 38721),\n",
       " (21341, 44825),\n",
       " (29006, 32879),\n",
       " (14647, 12356),\n",
       " (41133, 735),\n",
       " (3237, 46743),\n",
       " (22433, 52607),\n",
       " (21761, 38739),\n",
       " (27368, 39274),\n",
       " (8455, 49977),\n",
       " (20181, 29567),\n",
       " (6894, 44053),\n",
       " (40946, 31649),\n",
       " (19672, 38028),\n",
       " (31123, 21880),\n",
       " (36075, 52285),\n",
       " (4603, 26683),\n",
       " (12502, 54797),\n",
       " (10353, 42058),\n",
       " (11255, 36268),\n",
       " (22408, 32026),\n",
       " (30117, 42781),\n",
       " (35019, 224),\n",
       " (21815, 9295),\n",
       " (430, 46462),\n",
       " (26572, 54508),\n",
       " (5674, 15683),\n",
       " (3795, 52524),\n",
       " (20366, 40287),\n",
       " (29199, 46348),\n",
       " (7184, 23776),\n",
       " (11852, 52473),\n",
       " (15821, 18113),\n",
       " (26428, 47589),\n",
       " (38036, 42207),\n",
       " (40080, 478),\n",
       " (25067, 26972),\n",
       " (12574, 54794),\n",
       " (32658, 54704),\n",
       " (14516, 13054),\n",
       " (1710, 48027),\n",
       " (6588, 37607),\n",
       " (20849, 48927),\n",
       " (41613, 41214),\n",
       " (27837, 24984),\n",
       " (33056, 50549),\n",
       " (9464, 41522),\n",
       " (41793, 46285),\n",
       " (40101, 23168),\n",
       " (40786, 52547),\n",
       " (41803, 52894),\n",
       " (20688, 52244),\n",
       " (7983, 49362),\n",
       " (28571, 54484),\n",
       " (26823, 48734),\n",
       " (41367, 7452),\n",
       " (14714, 27712),\n",
       " (15289, 15377),\n",
       " (18823, 10365),\n",
       " (10488, 47857),\n",
       " (28542, 36935),\n",
       " (20259, 43355),\n",
       " (41287, 14518),\n",
       " (21441, 170),\n",
       " (1779, 19911),\n",
       " (33398, 10477),\n",
       " (8544, 52260),\n",
       " (9193, 44038),\n",
       " (41230, 923),\n",
       " (6182, 530),\n",
       " (38218, 19071),\n",
       " (33078, 18874),\n",
       " (8980, 46145),\n",
       " (32516, 33134),\n",
       " (22819, 22309),\n",
       " (24562, 19350),\n",
       " (28578, 52285),\n",
       " (11614, 19945),\n",
       " (18263, 9102),\n",
       " (34121, 4577),\n",
       " (20896, 50449),\n",
       " (1409, 12356),\n",
       " (29356, 9690),\n",
       " (8421, 32568),\n",
       " (29951, 42330),\n",
       " (35966, 38489),\n",
       " (31325, 47610),\n",
       " (37836, 36766),\n",
       " (38186, 19654),\n",
       " (13472, 9998),\n",
       " (27213, 35575),\n",
       " (7843, 23408),\n",
       " (17165, 32400),\n",
       " (26188, 45203),\n",
       " (24992, 14854),\n",
       " (32000, 35590),\n",
       " (4078, 55053),\n",
       " (3880, 50608),\n",
       " (35784, 27114),\n",
       " (41669, 42677),\n",
       " (26089, 44177),\n",
       " (15183, 54941),\n",
       " (42462, 27266),\n",
       " (7909, 38930),\n",
       " (24796, 54054),\n",
       " (226, 992),\n",
       " (14170, 42729),\n",
       " (8697, 36007),\n",
       " (40300, 38643),\n",
       " (19178, 42218),\n",
       " (9260, 9517),\n",
       " (35511, 47371),\n",
       " (37777, 25205),\n",
       " (21422, 291),\n",
       " (27627, 54934),\n",
       " (35829, 11436),\n",
       " (5551, 24475),\n",
       " (34519, 42772),\n",
       " (36003, 27538),\n",
       " (13758, 18999),\n",
       " (3301, 2528),\n",
       " (19971, 17129),\n",
       " (37214, 26933),\n",
       " (11014, 31189),\n",
       " (13351, 54044),\n",
       " (18306, 52209),\n",
       " (38996, 5886),\n",
       " (21895, 47170),\n",
       " (21286, 50058),\n",
       " (18977, 37101),\n",
       " (18972, 40406),\n",
       " (837, 40786),\n",
       " (12447, 51049),\n",
       " (32096, 47850),\n",
       " (37051, 52660),\n",
       " (23455, 50361),\n",
       " (35574, 17868),\n",
       " (1436, 11775),\n",
       " (26123, 52819),\n",
       " (7021, 54201),\n",
       " (17318, 23179),\n",
       " (5149, 33863),\n",
       " (25459, 23499),\n",
       " (1972, 45491),\n",
       " (4601, 4718),\n",
       " (32847, 55073),\n",
       " (36827, 51905),\n",
       " (27023, 3505),\n",
       " (35720, 29707),\n",
       " (1535, 25259),\n",
       " (37530, 42199),\n",
       " (8624, 9999),\n",
       " (14441, 47793),\n",
       " (33585, 26894),\n",
       " (9123, 786),\n",
       " (8047, 44367),\n",
       " (34992, 34337),\n",
       " (16086, 29215),\n",
       " (32195, 39053),\n",
       " (16814, 19071),\n",
       " (29269, 13854),\n",
       " (42264, 25843),\n",
       " (14344, 26397),\n",
       " (31115, 54407),\n",
       " (5398, 41104),\n",
       " (32444, 35593),\n",
       " (11619, 47985),\n",
       " (10590, 45369),\n",
       " (40485, 43374),\n",
       " (9953, 54611),\n",
       " (2734, 34335),\n",
       " (5798, 41977),\n",
       " (3476, 43539),\n",
       " (37768, 53977),\n",
       " (29168, 29199),\n",
       " (13844, 35092),\n",
       " (36665, 53132),\n",
       " (24260, 49310),\n",
       " (22589, 53606),\n",
       " (11322, 23037),\n",
       " (1905, 23341),\n",
       " (34185, 11246),\n",
       " (39978, 19141),\n",
       " (39341, 16046),\n",
       " (16421, 53906),\n",
       " (32799, 47956),\n",
       " (37040, 11315),\n",
       " (8971, 40113),\n",
       " (121, 50364),\n",
       " (32649, 28912),\n",
       " (38534, 55092),\n",
       " (18083, 53173),\n",
       " (21226, 14836),\n",
       " (28253, 44216),\n",
       " (29401, 24603),\n",
       " (13662, 2927),\n",
       " (11052, 1871),\n",
       " (23648, 27855),\n",
       " (20140, 21219),\n",
       " (19860, 54413),\n",
       " (27910, 26322),\n",
       " (25817, 46201),\n",
       " (19001, 43577),\n",
       " (10723, 50341),\n",
       " (16272, 43058),\n",
       " (27018, 17295),\n",
       " (25408, 4568),\n",
       " (8536, 32880),\n",
       " (41085, 8104),\n",
       " (28132, 12556),\n",
       " (28231, 25101),\n",
       " (34967, 54534),\n",
       " (15406, 45051),\n",
       " (1448, 18685),\n",
       " (17708, 37323),\n",
       " (34022, 2341),\n",
       " (16716, 11436),\n",
       " (37361, 47829),\n",
       " (13345, 53033),\n",
       " (4419, 15024),\n",
       " (17051, 51319),\n",
       " (30813, 27492),\n",
       " (10468, 54373),\n",
       " (7062, 26322),\n",
       " (15987, 54566),\n",
       " (34065, 52632),\n",
       " (30653, 44243),\n",
       " (38342, 3607),\n",
       " (18863, 47376),\n",
       " (15631, 54150),\n",
       " (10170, 53632),\n",
       " (18971, 46680),\n",
       " (26077, 7938),\n",
       " (21690, 27492),\n",
       " (28080, 28473),\n",
       " (10263, 36598),\n",
       " (13356, 49142),\n",
       " (22299, 38567),\n",
       " (36548, 46386),\n",
       " (10560, 54497),\n",
       " (15863, 43546),\n",
       " (15265, 12594),\n",
       " (1752, 35368),\n",
       " (14536, 33359),\n",
       " (20336, 33831),\n",
       " (10059, 35492),\n",
       " (17832, 38126),\n",
       " (13611, 54966),\n",
       " (25615, 54014),\n",
       " (6793, 34805),\n",
       " (26668, 16377),\n",
       " (2297, 28523),\n",
       " (26625, 51433),\n",
       " (29122, 1873),\n",
       " (6966, 34962),\n",
       " (19498, 11269),\n",
       " (8672, 49346),\n",
       " (23407, 49511),\n",
       " (19501, 48427),\n",
       " (13588, 33556),\n",
       " (27637, 35608),\n",
       " (6155, 12533),\n",
       " (32015, 50694),\n",
       " (32313, 41757),\n",
       " (1780, 52998),\n",
       " (41792, 5821),\n",
       " (32132, 54662),\n",
       " (12976, 23499),\n",
       " (41607, 49869),\n",
       " (8774, 19421),\n",
       " (3477, 8983),\n",
       " (13801, 26322),\n",
       " (16176, 11525),\n",
       " (31134, 28206),\n",
       " (38607, 51782),\n",
       " (11666, 50405),\n",
       " (42151, 53645),\n",
       " (11143, 46917),\n",
       " (1900, 50592),\n",
       " (3930, 6979),\n",
       " (4480, 25876),\n",
       " (22466, 38168),\n",
       " (18028, 50092),\n",
       " (13694, 17070),\n",
       " (5254, 16868),\n",
       " (23161, 39218),\n",
       " (38357, 31605),\n",
       " (6030, 52552),\n",
       " (6897, 47936),\n",
       " (38023, 54885),\n",
       " (27414, 51377),\n",
       " (40635, 43936),\n",
       " (33211, 41981),\n",
       " (19287, 54109),\n",
       " (3070, 19074),\n",
       " (32355, 17564),\n",
       " (12500, 50688),\n",
       " (15184, 45314),\n",
       " (17257, 54796),\n",
       " (12514, 28406),\n",
       " (7221, 34154),\n",
       " (20113, 4580),\n",
       " (927, 36328),\n",
       " (11605, 31564),\n",
       " (30362, 49395),\n",
       " (39945, 18764),\n",
       " (36005, 49395),\n",
       " (6184, 6013),\n",
       " (15000, 43921),\n",
       " (15158, 45261),\n",
       " (29656, 1648),\n",
       " (5932, 50300),\n",
       " (22285, 23840),\n",
       " (34639, 47847),\n",
       " (37471, 51002),\n",
       " (9556, 18911),\n",
       " (24337, 50683),\n",
       " (27114, 46483),\n",
       " (2904, 31405),\n",
       " (4737, 52017),\n",
       " (41978, 25299),\n",
       " (29327, 18038),\n",
       " (13440, 37323),\n",
       " (17624, 49197),\n",
       " (8141, 26287),\n",
       " (39607, 51320),\n",
       " (40536, 34787),\n",
       " (29626, 23703),\n",
       " (26812, 33205),\n",
       " (32859, 55017),\n",
       " (41721, 24855),\n",
       " (34846, 54862),\n",
       " (40851, 45415),\n",
       " (3781, 48603),\n",
       " (39495, 41172),\n",
       " (4947, 16027),\n",
       " (5096, 32594),\n",
       " (21859, 36806),\n",
       " (40683, 40849),\n",
       " (1209, 53437),\n",
       " (4376, 22856),\n",
       " (350, 47785),\n",
       " (4909, 54581),\n",
       " (6659, 51810),\n",
       " (38319, 6493),\n",
       " (13937, 34988),\n",
       " (7605, 39647),\n",
       " (2929, 52645),\n",
       " (3363, 4642),\n",
       " (20697, 51983),\n",
       " (1654, 40174),\n",
       " (436, 45758),\n",
       " (34293, 54807),\n",
       " (6460, 28188),\n",
       " (19326, 37323),\n",
       " (13256, 24912),\n",
       " (1298, 48877),\n",
       " (12663, 41845),\n",
       " (24679, 38732),\n",
       " (13300, 53248),\n",
       " (37137, 47813),\n",
       " (35599, 45808),\n",
       " (3271, 50315),\n",
       " (37520, 20224),\n",
       " (42292, 40899),\n",
       " (24243, 42780),\n",
       " (1159, 13026),\n",
       " (19245, 26488),\n",
       " (4714, 38433),\n",
       " (16115, 23676),\n",
       " (30295, 19381),\n",
       " (9626, 36228),\n",
       " (12146, 11461),\n",
       " (12064, 46626),\n",
       " (12749, 26020),\n",
       " (25619, 54522),\n",
       " (25017, 12080),\n",
       " (4370, 50637),\n",
       " (10571, 49467),\n",
       " (32436, 54109),\n",
       " (15669, 37101),\n",
       " ...}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_item_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547,\n",
       " 20547]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[20547]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "157e00db7a184aa5a030624726b672ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bca2d5ef10240f9999efc8e2f60583e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91b4a9a47056433e934cf949d84a44a9",
      "max": 2015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce70bf4472bd4660a413a819b4f77f6f",
      "value": 2015
     }
    },
    "1d367a928d4b47ba978e1abc49800928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f25f90b36b24da5b2c658e16829fcd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fdf7d5bc28e4e208ae17cee915035eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_157e00db7a184aa5a030624726b672ff",
      "placeholder": "​",
      "style": "IPY_MODEL_1d367a928d4b47ba978e1abc49800928",
      "value": "Epoch 14: 100%"
     }
    },
    "91b4a9a47056433e934cf949d84a44a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0432ada792a49c0a5b11a5ab7c8c43b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce70bf4472bd4660a413a819b4f77f6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5ea92a1d80c43a1a8fa3264275892fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f25f90b36b24da5b2c658e16829fcd9",
      "placeholder": "​",
      "style": "IPY_MODEL_a0432ada792a49c0a5b11a5ab7c8c43b",
      "value": " 2015/2015 [01:05&lt;00:00, 30.85it/s, loss=0.364, v_num=5]"
     }
    },
    "df1a38e7d30148c7aa6c8036d8ac074b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fdf7d5bc28e4e208ae17cee915035eb",
       "IPY_MODEL_1bca2d5ef10240f9999efc8e2f60583e",
       "IPY_MODEL_d5ea92a1d80c43a1a8fa3264275892fc"
      ],
      "layout": "IPY_MODEL_e6688f220b1044ad8c2982bc685d96ff"
     }
    },
    "e6688f220b1044ad8c2982bc685d96ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
